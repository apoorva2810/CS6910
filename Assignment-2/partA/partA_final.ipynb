{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "partA_final.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5W1kM045hBvB1Ylu76w73",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apoorva2810/CS6910/blob/main/Assignment-2/partA/partA_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANyXSLdF1qZq"
      },
      "source": [
        "#Before executing the code, allocate GPU in Colab from: Edit -> Notebook Settings -> Hardware accelerator -> GPU"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsOSjZml2E9F"
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense,BatchNormalization\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "import random\n",
        "import os\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras import layers, models, Model, optimizers\n",
        "import tensorflow.keras as K\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn import preprocessing  \n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03_4BtSq3UuB"
      },
      "source": [
        "#To access content from google drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mreYDBi73qlM"
      },
      "source": [
        "#Todo- first rename the file in drive\n",
        "#Use this link: https://drive.google.com/drive/folders/1yu5DuYlM_cvV5qwIKKnl3sHRG_G41aLB?usp=sharing\n",
        "#To make copy of pickled data and save it folder name 'Raw_data350'\n",
        "\n",
        "with open('/content/gdrive/My Drive/Raw_data350/xtrain','rb') as xT:\n",
        "  xTrain = pickle.load(xT)\n",
        "\n",
        "with open('/content/gdrive/My Drive/Raw_data350/ytrain','rb') as yT:\n",
        "  yTrain = pickle.load(yT)\n",
        "\n",
        "with open('/content/gdrive/My Drive/Raw_data350/xtest','rb') as xV:\n",
        "  xTest = pickle.load(xV)\n",
        "\n",
        "with open('/content/gdrive/My Drive/Raw_data350/ytest','rb') as yV:\n",
        "  yTest = pickle.load(yV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W42SpIgx36u0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}